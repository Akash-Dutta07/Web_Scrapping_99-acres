{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e1598eb",
   "metadata": {},
   "source": [
    "## Refactor the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b168130a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "\n",
    "class PropertyScraper:\n",
    "    def __init__(self, url, timeout=7):\n",
    "        self.url = url\n",
    "        self.data = []\n",
    "        self.driver = self._initialize_driver()\n",
    "        self.wait = WebDriverWait(self.driver, timeout= timeout)\n",
    "    \n",
    "    def _initialize_driver(self):\n",
    "    # options\n",
    "       chrome_options = Options()\n",
    "       chrome_options.add_argument(\"--disable-http2\")\n",
    "       chrome_options.add_argument(\"--incognito\")\n",
    "       chrome_options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "       chrome_options.add_argument(\"--ignore-certificate-errors\")\n",
    "       chrome_options.add_argument(\"--enable-features=NetworkServiceInProcess\")\n",
    "       chrome_options.add_argument(\"--disable-features=NetworkService\")\n",
    "       chrome_options.add_argument(\n",
    "        \"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0.4577.63 Safari/537.36\"\n",
    "    )\n",
    "\n",
    "       driver = webdriver.Chrome(options=chrome_options)\n",
    "       driver.maximize_window()\n",
    "       return driver\n",
    "   \n",
    "      #-------------------------------------------------------------------#\n",
    "      ###################################################################   \n",
    "    \n",
    "    def _wait_for_page_to_load(self):\n",
    "        title = self.driver.title\n",
    "        try:\n",
    "           self.wait.until(\n",
    "            lambda d: d.execute_script(\"return document.readyState\") == \"complete\"\n",
    "        )\n",
    "        except:\n",
    "           print(f'The webpage \"{title}\" did not get fully loaded.\\n')\n",
    "        else:\n",
    "           print(f'The webpage \"{title}\" did get fully loaded.\\n')\n",
    "\n",
    "      #-------------------------------------------------------------------#   \n",
    "      ####################################################################   \n",
    "    \n",
    "    \n",
    "    def access_website(self):\n",
    "        self.driver.get(self.url)\n",
    "        self._wait_for_page_to_load()\n",
    "    \n",
    "      #-------------------------------------------------------------------#\n",
    "      #####################################################################\n",
    "    \n",
    "    \n",
    "    def search_properties(self, text):\n",
    "        # identify and enter text into search bar\n",
    "        try:\n",
    "            search_bar = self.wait.until(\n",
    "                EC.presence_of_element_located((By.XPATH, '//*[@id=\"keyword2\"]'))\n",
    "            )\n",
    "        except:\n",
    "            print(\"Timeout while locating Search Bar.\\n\")\n",
    "        else:\n",
    "            search_bar.send_keys(text)\n",
    "            time.sleep(5)\n",
    "        \n",
    "        # selecting valid option from list\n",
    "        try:\n",
    "            valid_option = self.wait.until(\n",
    "                EC.element_to_be_clickable((By.XPATH, '//*[@id=\"0\"]'))\n",
    "            )\n",
    "        except:\n",
    "            print(\"Timeout while locating valid search option.\\n\")\n",
    "        else:\n",
    "            valid_option.click()\n",
    "            time.sleep(2)\n",
    "\n",
    "        # click on Search button\n",
    "        try:\n",
    "            search_button = self.wait.until(\n",
    "                EC.element_to_be_clickable((By.XPATH, '//*[@id=\"searchform_search_btn\"]'))\n",
    "            )\n",
    "        except:\n",
    "            print(\"Timeout while clicking on \\\"Search\\\" button.\\n\")\n",
    "        else:\n",
    "            search_button.click()\n",
    "            self._wait_for_page_to_load()\n",
    "   #-------------------------------------------------------------------# \n",
    "   ####################################################################\n",
    "   \n",
    "       \n",
    "    \n",
    "    def adjust_budget_slider(self, offset):\n",
    "        # adjust the Budget slider\n",
    "        try:\n",
    "            slider = self.wait.until(\n",
    "                EC.element_to_be_clickable((By.XPATH, '//*[@id=\"budgetLeftFilter_max_node\"]'))\n",
    "            )\n",
    "        except:\n",
    "            print(\"Timeout while clicking on Budget slider circle.\\n\")\n",
    "        else:\n",
    "            actions = ActionChains(self.driver)\n",
    "            (\n",
    "                actions\n",
    "                .click_and_hold(slider)\n",
    "                .move_by_offset(offset, 0)\n",
    "                .release()\n",
    "                .perform()\n",
    "            )\n",
    "            time.sleep(2)\n",
    "    \n",
    "      #-------------------------------------------------------------------#   \n",
    "      #####################################################################\n",
    "      \n",
    "    \n",
    "    \n",
    "    def apply_filters(self):\n",
    "        # filter results to show genuine listings\n",
    "# 1. Verified\n",
    "        verified = self.wait.until(\n",
    "            EC.element_to_be_clickable((By.XPATH, '/html[1]/body[1]/div[1]/div[1]/div[1]/div[4]/div[3]/div[1]/div[3]/section[1]/div[1]/div[1]/div[1]/div[1]/div[1]/div[1]/div[3]/span[2]'))\n",
    "        )\n",
    "        verified.click()\n",
    "        time.sleep(2)\n",
    "\n",
    "        # 2. Ready To Move\n",
    "        ready_to_move = self.wait.until(\n",
    "            EC.element_to_be_clickable((By.XPATH, '/html[1]/body[1]/div[1]/div[1]/div[1]/div[4]/div[3]/div[1]/div[3]/section[1]/div[1]/div[1]/div[1]/div[1]/div[1]/div[1]/div[3]/span[2]'))\n",
    "        )\n",
    "        ready_to_move.click()\n",
    "        time.sleep(2)\n",
    "\n",
    "\n",
    "        # moving to the right side to unhide remaining filters\n",
    "        while True:\n",
    "            try:\n",
    "                filter_right_button = self.wait.until(\n",
    "                    EC.presence_of_element_located((By.XPATH, \"/html[1]/body[1]/div[1]/div[1]/div[1]/div[4]/div[3]/div[1]/div[3]/section[1]/div[1]/div[1]/div[1]/div[1]/div[2]/i[1]\"))\n",
    "                )\n",
    "            except:\n",
    "                print(\"Timeout because we have uncovered all filters.\\n\")\n",
    "                break\n",
    "            else:\n",
    "                filter_right_button.click()\n",
    "                time.sleep(1)\n",
    "        \n",
    "\n",
    "        # 3. With Photos\n",
    "        with_photos = self.wait.until(\n",
    "            EC.element_to_be_clickable((By.XPATH, '/html[1]/body[1]/div[1]/div[1]/div[1]/div[4]/div[3]/div[1]/div[3]/section[1]/div[1]/div[1]/div[1]/div[1]/div[2]/div[1]/div[6]/span[2]'))\n",
    "        )\n",
    "        with_photos.click()\n",
    "        time.sleep(2)\n",
    "\n",
    "        # 4. With Videos\n",
    "        with_videos = self.wait.until(\n",
    "            EC.element_to_be_clickable((By.XPATH, '/html[1]/body[1]/div[1]/div[1]/div[1]/div[4]/div[3]/div[1]/div[3]/section[1]/div[1]/div[1]/div[1]/div[1]/div[2]/div[1]/div[7]/span[2]'))\n",
    "        )\n",
    "        with_videos.click()\n",
    "        time.sleep(4)\n",
    "    #-------------------------------------------------------------------#   \n",
    "    #####################################################################\n",
    "            \n",
    "    def _extract_data(self, row, by, value):\n",
    "        try:\n",
    "                return row.find_element(by, value).text\n",
    "        except:\n",
    "                return np.nan\n",
    "###############################################################################################################################\n",
    "##############################################################################################################################\n",
    "\n",
    "    def scrape_webpage(self):\n",
    "        rows = self.driver.find_elements(\n",
    "            By.CSS_SELECTOR,\n",
    "            \".tupleNew__contentWrap, .PseudoTupleRevamp__contentWrapAb\"\n",
    "        )\n",
    "\n",
    "        for row in rows:\n",
    "            property = {\n",
    "                \"name\": self._extract_data(\n",
    "                    row, By.CSS_SELECTOR, \".tupleNew__headingNrer, .PseudoTupleRevamp__headNrating\"\n",
    "                ),\n",
    "                \"location\": self._extract_data(\n",
    "                    row, By.CSS_SELECTOR, \".tupleNew__propType, .PseudoTupleRevamp__w400Ml4\"\n",
    "                ),\n",
    "                \"price\": self._extract_data(\n",
    "                    row, By.CSS_SELECTOR, \".tupleNew__priceValWrap, .configs__ccl2\"\n",
    "                )\n",
    "            }\n",
    "\n",
    "            # --- Robust fallback logic for area and bhk ---\n",
    "            try:\n",
    "                elements = row.find_elements(By.CSS_SELECTOR, \".tupleNew__area1Type\")\n",
    "\n",
    "                if len(elements) >= 2:\n",
    "                    area, bhk = [ele.text for ele in elements[:2]]\n",
    "                elif len(elements) == 1:\n",
    "                    area = elements[0].text\n",
    "                    # Try to extract bhk from configs__ccl1\n",
    "                    try:\n",
    "                        bhk = row.find_element(By.CSS_SELECTOR, \".configs__ccl1\").text\n",
    "                    except:\n",
    "                        bhk = np.nan\n",
    "                else:\n",
    "                    # No valid elements, fallback directly\n",
    "                    area = np.nan\n",
    "                    try:\n",
    "                        bhk = row.find_element(By.CSS_SELECTOR, \".configs__ccl1\").text\n",
    "                    except:\n",
    "                        bhk = np.nan\n",
    "\n",
    "            except:\n",
    "                # Entire block failed\n",
    "                area, bhk = [np.nan, np.nan]\n",
    "\n",
    "            property[\"area\"] = area\n",
    "            property[\"bhk\"] = bhk\n",
    "\n",
    "            # Do something with `property` here — store it or print it\n",
    "            self.data.append(property)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "  #######################################################################################################################\n",
    "  #######################################################################################################################                                     \n",
    "    \n",
    "    def navigate_pages_scrape_data(self):\n",
    "        page_count = 0\n",
    "        while True:\n",
    "            try:\n",
    "                self.scrape_webpage()\n",
    "                next_page_button = self.driver.find_element(By.XPATH, \"//a[normalize-space()='Next Page >']\")\n",
    "            except:\n",
    "                print(\"Timeout beacuse we have navigated this many {page_count} pages. \\n\")\n",
    "                break\n",
    "            else:\n",
    "                try:\n",
    "                    self.driver.execute_script(\"window.scrollBy(0, arguments[0].getBoundingClientRect().top - 100);\", next_page_button)\n",
    "                    time.sleep(2)\n",
    "                    self.wait.until(\n",
    "                        EC.element_to_be_clickable((By.XPATH, \"//a[normalize-space()='Next Page >']\"))\n",
    "                    ).click()\n",
    "                    time.sleep(5)\n",
    "                except:\n",
    "                        print(\"TimeOut on clicking on \\\"Next Page\\\".\\n\")\n",
    "                     \n",
    "    \n",
    "    #########################################################################################################################\n",
    "    #########################################################################################################################\n",
    "    \n",
    "    def clean_data_and_save_as_excel(self, file_name):\n",
    "        df_properties = (\n",
    "            pd\n",
    "            .DataFrame(self.data).drop_duplicates()\n",
    "            .apply(lambda col: col.str.strip().str.lower() if col.dtype == \"object\" else col)\n",
    "            .assign(\n",
    "            is_starred=lambda df_: df_.name.str.contains(\"\\n\").astype(int),\n",
    "            name=lambda df_: (\n",
    "                df_\n",
    "                .name\n",
    "                .str.replace(\"\\n[0-9.]+\", \"\", regex=True)\n",
    "                .str.strip()\n",
    "            ),\n",
    "            #location\n",
    "            location = lambda df_: (\n",
    "            df_\n",
    "            .location\n",
    "            .str.split(\" in \").str[-1].str.strip().str.replace(\", \", \",\").str.replace(r\"^in\\s+\", \"\", regex=True)\n",
    "        ),\n",
    "        #price\n",
    "        price = lambda df_: (\n",
    "            df_\n",
    "            .price\n",
    "            .str.replace(\"₹\", \"\", regex=False)\n",
    "            .str.replace(\"p\", \"\", regex=False)\n",
    "            .apply(\n",
    "            lambda val: 0.0 if \"request\" in val.lower()\n",
    "            else (\n",
    "                # If range exists, average both ends\n",
    "                sum([\n",
    "                    float(\n",
    "                        v.replace(\"lac\", \"\")\n",
    "                        .replace(\"l\", \"\")\n",
    "                        .replace(\"cr\", \"\")\n",
    "                        .replace(\"₹\", \"\")\n",
    "                        .strip()\n",
    "                    )\n",
    "                    for v in val.lower().split(\"-\")\n",
    "                ]) / 2\n",
    "                if \"-\" in val else float(\n",
    "                    val.lower()\n",
    "                    .replace(\"lac\", \"\")\n",
    "                    .replace(\"l\", \"\")\n",
    "                    .replace(\"cr\", \"\")\n",
    "                    .replace(\"₹\", \"\")\n",
    "                    .strip()\n",
    "                )\n",
    "            ) * (\n",
    "                1 if any(x in val.lower() for x in [\"lac\", \"l\"]) else 100\n",
    "            )\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "        ),\n",
    "        #Area\n",
    "        area = lambda df_: (\n",
    "            df_\n",
    "            .area\n",
    "            .str.replace(\"sqft\", \"\", regex=False)\n",
    "            .str.strip()\n",
    "            .astype(float)\n",
    "            # repalced Nan with median of Area\n",
    "            .fillna(df_.area.str.replace(\"sqft\", \"\", regex=False).str.strip().astype(float).median())\n",
    "            .pipe(lambda ser: pd.to_numeric(ser))\n",
    "            \n",
    "            \n",
    "        ),\n",
    "        #BHK\n",
    "        bHK = lambda df_: (\n",
    "            df_\n",
    "            .bHK\n",
    "            .str.extract(r\"(\\d+)\\s*bhk\", expand=False)  # extract number\n",
    "            .fillna(0)                                   # fill NaNs as 0\n",
    "            .astype(int)                                 # convert to integer\n",
    "        )\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "            \n",
    "        ).rename(columns={\"price\": \"Price_lakhs\",\n",
    "                        \"area\" : \"Area_sqft\"})\n",
    "        \n",
    "\n",
    "\n",
    "        )\n",
    "        df_properties.to_excel(f\"{file_name}.xlxs\",index = False)\n",
    "        \n",
    "    ###############################################################################################################################\n",
    "    #################################################################################################################################\n",
    "\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    def run(self, text= \"chennai\", offset= -100, file_name = \"properties\"):\n",
    "        try :\n",
    "            self.access_website()\n",
    "            self.search_properties(text)\n",
    "            self.adjust_budget_slider(offset)\n",
    "            self.apply_filters()\n",
    "            self.navigate_pages_scrape_data()\n",
    "            self.clean_data_and_save_as_excel(file_name)\n",
    "        finally :\n",
    "            time.sleep(2)\n",
    "            self.driver.quit()\n",
    "    \n",
    "    \n",
    "    #-------------------------------------------------------------------#   \n",
    "    ####################################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "        scrapper = PropertyScraper(url=\"https://www.99acres.com/\") \n",
    "        scrapper.run(text =\"Kolkata\", offset= -73, file_name= \"kolkata_properties\")\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d88c571",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "99-acres",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
